# Generated by roxygen2: do not edit by hand

S3method(bake,step_lda)
S3method(bake,step_lemma)
S3method(bake,step_ngram)
S3method(bake,step_pos_filter)
S3method(bake,step_sequence_onehot)
S3method(bake,step_stem)
S3method(bake,step_stopwords)
S3method(bake,step_text_normalization)
S3method(bake,step_textfeature)
S3method(bake,step_texthash)
S3method(bake,step_tf)
S3method(bake,step_tfidf)
S3method(bake,step_tokenfilter)
S3method(bake,step_tokenize)
S3method(bake,step_tokenmerge)
S3method(bake,step_untokenize)
S3method(bake,step_word_embeddings)
S3method(format,textrecipes_tokenlist)
S3method(obj_print_footer,textrecipes_tokenlist)
S3method(prep,step_lda)
S3method(prep,step_lemma)
S3method(prep,step_ngram)
S3method(prep,step_pos_filter)
S3method(prep,step_sequence_onehot)
S3method(prep,step_stem)
S3method(prep,step_stopwords)
S3method(prep,step_text_normalization)
S3method(prep,step_textfeature)
S3method(prep,step_texthash)
S3method(prep,step_tf)
S3method(prep,step_tfidf)
S3method(prep,step_tokenfilter)
S3method(prep,step_tokenize)
S3method(prep,step_tokenmerge)
S3method(prep,step_untokenize)
S3method(prep,step_word_embeddings)
S3method(print,step_lda)
S3method(print,step_lemma)
S3method(print,step_ngram)
S3method(print,step_pos_filter)
S3method(print,step_sequence_onehot)
S3method(print,step_stem)
S3method(print,step_stopwords)
S3method(print,step_text_normalization)
S3method(print,step_textfeature)
S3method(print,step_texthash)
S3method(print,step_tf)
S3method(print,step_tfidf)
S3method(print,step_tokenfilter)
S3method(print,step_tokenize)
S3method(print,step_tokenmerge)
S3method(print,step_untokenize)
S3method(print,step_word_embeddings)
S3method(tidy,step_lda)
S3method(tidy,step_lemma)
S3method(tidy,step_ngram)
S3method(tidy,step_pos_filter)
S3method(tidy,step_sequence_onehot)
S3method(tidy,step_stem)
S3method(tidy,step_stopwords)
S3method(tidy,step_text_normalization)
S3method(tidy,step_textfeature)
S3method(tidy,step_texthash)
S3method(tidy,step_tf)
S3method(tidy,step_tfidf)
S3method(tidy,step_tokenfilter)
S3method(tidy,step_tokenize)
S3method(tidy,step_tokenmerge)
S3method(tidy,step_untokenize)
S3method(tidy,step_word_embeddings)
S3method(vec_ptype_abbr,textrecipes_tokenlist)
S3method(vec_restore,textrecipes_tokenlist)
export("%>%")
export(step_lda)
export(step_lemma)
export(step_ngram)
export(step_pos_filter)
export(step_sequence_onehot)
export(step_stem)
export(step_stopwords)
export(step_text_normalization)
export(step_textfeature)
export(step_texthash)
export(step_tf)
export(step_tfidf)
export(step_tokenfilter)
export(step_tokenize)
export(step_tokenmerge)
export(step_untokenize)
export(step_word_embeddings)
export(tokenlist)
export(tunable.step_ngram)
importFrom(Matrix,sparseMatrix)
importFrom(Rcpp,sourceCpp)
importFrom(dplyr,bind_cols)
importFrom(dplyr,inner_join)
importFrom(dplyr,mutate_all)
importFrom(dplyr,rename_all)
importFrom(dplyr,select)
importFrom(dplyr,summarize_all)
importFrom(generics,tidy)
importFrom(magrittr,"%>%")
importFrom(purrr,keep)
importFrom(purrr,map)
importFrom(purrr,map_chr)
importFrom(purrr,map_dfc)
importFrom(purrr,map_dfr)
importFrom(purrr,map_lgl)
importFrom(purrr,pmap)
importFrom(recipes,add_step)
importFrom(recipes,bake)
importFrom(recipes,check_type)
importFrom(recipes,ellipse_check)
importFrom(recipes,is_trained)
importFrom(recipes,names0)
importFrom(recipes,prep)
importFrom(recipes,printer)
importFrom(recipes,rand_id)
importFrom(recipes,sel2char)
importFrom(recipes,step)
importFrom(recipes,terms_select)
importFrom(rlang,"%||%")
importFrom(rlang,.data)
importFrom(rlang,expr)
importFrom(rlang,na_chr)
importFrom(rlang,na_int)
importFrom(rlang,na_lgl)
importFrom(tibble,as_tibble)
importFrom(tibble,tibble)
importFrom(tidyr,unnest)
importFrom(vctrs,new_vctr)
importFrom(vctrs,obj_print_footer)
importFrom(vctrs,vec_assert)
importFrom(vctrs,vec_cast)
importFrom(vctrs,vec_ptype_abbr)
importFrom(vctrs,vec_restore)
useDynLib(textrecipes, .registration = TRUE)
